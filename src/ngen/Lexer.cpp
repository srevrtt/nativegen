#include <iostream>
#include <string>

#include "../include/Utils.hpp"
#include "include/Lexer.hpp"

// FIXME: string after string causes infiite loop
// TODO: unexpected token error

// Skips any unneeded whitespace
void Lexer::skipWhitespace()
{
  while (isspace(src[idx]))
  {
    idx++;
  }
}

// Tokenizes a string
std::string Lexer::tokenizeString()
{
  std::string str = "\"";

  while (src[idx] != '"')
  {
    str += src[idx];
    idx++;
  }

  if (src[idx] != '"')
  {
    Utilities::fatalError("Missing ending '\"' after string.");
  }

  str += '"';

  idx++;
  skipWhitespace();

  return str;
}

// Tokenizes a group of letters
std::string Lexer::tokenizeLetters()
{
  std::string letters;

  while (isalpha(src[idx]) || src[idx] == '_')
  {
    letters += src[idx];
    idx++;
  }

  return letters;
}

// Tokenizes an array
void Lexer::tokenizeArray()
{
  skipWhitespace();

  while (src[idx] != ']')
  {
    if (src[idx] == '"')
    {
      idx++;

      tkns.push_back(Token {"$T_STRING", tokenizeString()});
      skipWhitespace();
    }

    if (src[idx] == ']')
    {
      idx++;
      break;
    }

    if (src[idx] != ',')
    {
      Utilities::fatalError("Expected ',' after item in array.");
    }

    tkns.push_back(Token {"$T_COMMA", ","});
    skipWhitespace();

    idx++;
    skipWhitespace();
  }
}

// Creates a new lexer
Lexer::Lexer(std::string src)
{
  idx = 0;
  this->src = src;

  while (idx < src.length() - 1)
  {
    skipWhitespace();
    std::string letters = tokenizeLetters();
    skipWhitespace();

    if (src[idx] == ':')
    {
      tkns.push_back(Token {"$T_LETTERS", letters});
      tkns.push_back(Token {"$T_COLON", ":"});

      skipWhitespace();
      idx++;
      skipWhitespace();

      if (src[idx] == '"' || src[idx] == '[')
      {
        if (src[idx] == '"')
        {
          idx++;
          tkns.push_back(Token {"$T_STRING", tokenizeString()});
        }
        else if (src[idx] == '[')
        {
          idx++;
          skipWhitespace();

          tkns.push_back(Token {"$T_LEFT_BRACKET", "["});

          Lexer::tokenizeArray();
          tkns.push_back(Token {"$T_RIGHT_BRACKET", "]"});
        }
      }
    }

    skipWhitespace();
  }
}

// Gets all of the tokens generated by the lexer
std::vector<Token> Lexer::getTokens()
{
  return tkns;
}
